# ğŸ§  Anamnez AI

**AI-Powered Clinical Anamnesis Assistant**  
A real-time voice-to-structured-report system for medical professionals, leveraging local speech-to-text (OpenAI Whisper) and large language models for intelligent clinical documentation.

---

## ğŸ“‹ Overview

Anamnez AI is a full-stack clinical assistant application designed to streamline patient anamnesis collection. It captures patient interviews via voice, transcribes them locally using OpenAI Whisper STT, and generates structured medical reports through LLM-powered analysis â€” all while ensuring data privacy and offline capability.

**Key differentiators:**
- **100% Local STT**: No dependency on cloud APIs for voice transcription (HIPAA/GDPR-friendly).
- **Real-time processing**: WebSocket-based architecture for instant feedback.
- **Modular & scalable**: Clean separation of concerns using Flask Blueprints.
- **Production-ready**: Fully containerized with Docker Compose for one-command deployment.

---

## âœ¨ Key Features

- ğŸ¤ **Real-time Speech-to-Text**: Browser-based audio capture â†’ Local Whisper transcription (Turkish optimized)
- ğŸ¤– **AI Report Generation**: LLM-powered (OpenRouter API) psychological analysis and structured summaries
- ğŸ‘¨â€âš•ï¸ **Multi-Persona Psychologists**: 4 distinct AI counselor personalities (empathetic, professional, direct, warm)
- ğŸ”’ **Session Management**: Flask-Login authentication with role-based access control
- ğŸ“Š **SQLite Persistence**: Patient answers and test results stored with SQLAlchemy ORM
- ğŸŒ **WebSocket Communication**: Flask-SocketIO for bidirectional real-time messaging
- ğŸ³ **Docker Ready**: One-command deployment with persistent Whisper model caching
- ğŸŒ™ **Dark Mode**: Full UI theme switcher with localStorage persistence

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.10+** (Type-hinted, modular design)
- **Flask 3.1** (Blueprints for route separation)
- **Flask-SocketIO 5.6** (Real-time WebSocket events)
- **Flask-SQLAlchemy 3.1** (ORM layer)
- **Flask-Login 0.6** (Session auth)
- **OpenAI Whisper** (Local STT â€” `small` model, ~461MB)

### Frontend
- **HTML5 + Tailwind CSS 3.x** (Responsive UI)
- **Socket.IO Client 4.7** (WebSocket connection)
- **MediaRecorder API** (Browser audio capture)
- **html2pdf.js** (Client-side PDF export)

### DevOps
- **Docker + Docker Compose** (Containerization)
- **FFmpeg** (Audio processing for Whisper)
- **Persistent Volumes** (Whisper model cache to prevent re-downloads)

### External Services
- **OpenRouter API** (LLM inference â€” GPT-3.5-turbo)

---

## ğŸš€ Quick Start

### Prerequisites
- **Docker Desktop** (macOS/Windows) or **Docker Engine + Docker Compose** (Linux)
- **8GB+ RAM** recommended (Whisper model loading)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/anamnez-ai.git
   cd anamnez-ai
   ```

2. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENROUTER_API_KEY
   ```

3. **Build and run with Docker Compose**
   ```bash
   docker compose up --build
   ```

4. **Access the application**
   ```
   http://localhost:5001
   ```

### First-time Setup
On the first launch, Whisper will download the `small` model (~461MB) to `/root/.cache/whisper` inside the container. This is cached in a persistent volume, so subsequent restarts are instant.

---

## ğŸ“ Project Structure

```
Anamnez-GPT/
â”œâ”€â”€ run.py                      # Application entry point
â”œâ”€â”€ config.py                   # Environment-based configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Container build instructions
â”œâ”€â”€ docker-compose.yml          # Multi-container orchestration
â”œâ”€â”€ .dockerignore               # Build context exclusions
â”œâ”€â”€ .env.example                # Environment variable template
â”œâ”€â”€ .gitignore                  # Version control exclusions
â”‚
â”œâ”€â”€ app/                        # Main application package
â”‚   â”œâ”€â”€ __init__.py             # Flask factory (create_app)
â”‚   â”œâ”€â”€ models.py               # SQLAlchemy models (User, Answer, TestResult)
â”‚   â”œâ”€â”€ routes.py               # HTTP routes (Blueprint)
â”‚   â”œâ”€â”€ socket_events.py        # SocketIO event handlers + Whisper integration
â”‚   â”œâ”€â”€ services.py             # Business logic (LLM API calls)
â”‚   â”œâ”€â”€ constants.py            # Static data (psychologist personas)
â”‚   â”‚
â”‚   â”œâ”€â”€ templates/              # Jinja2 HTML templates
â”‚   â”‚   â”œâ”€â”€ login.html
â”‚   â”‚   â”œâ”€â”€ select_style.html
â”‚   â”‚   â”œâ”€â”€ questions.html      # Real-time chat interface
â”‚   â”‚   â””â”€â”€ result.html         # AI-generated report
â”‚   â”‚
â”‚   â””â”€â”€ static/                 # CSS/JS assets (currently inline in templates)
â”‚
â””â”€â”€ instance/                   # Runtime data (SQLite DB)
    â””â”€â”€ anamnez_gpt.db
```

---

## ğŸ§ª Usage

### 1. Login
**Default Test Credentials** (Auto-seeded on first launch):
```
Username: test
Password: test123
```

> **Note**: To make the system ready-to-use out of the box, an automatic database seeding mechanism has been implemented within the application factory. When deployed in a new environment, the default test account is automatically created without manual database intervention. This ensures zero-friction onboarding for demonstrations and testing.

<details>
<summary>Manual user creation (optional)</summary>

You can also create additional users via Flask shell:
```bash
docker compose exec anamnez-ai flask shell
>>> from app.models import User, db
>>> from werkzeug.security import generate_password_hash
>>> user = User(username='doctor', password_hash=generate_password_hash('password'), role='user')
>>> db.session.add(user)
>>> db.session.commit()
```
</details>

### 2. Select AI Psychologist
Choose from 4 personas:
- **Ä°rem** (Warm & Friendly)
- **TuÄŸrul** (Professional & Experienced)
- **Yasemin** (Empathetic & Emotional)
- **Ali** (Realistic & Direct)

### 3. Conduct Interview
- **Type**: Use text input for written responses
- **Voice**: Click ğŸ¤ to record audio (Whisper transcribes locally)
- AI adapts questioning based on conversation depth (5-10 messages)

### 4. View Report
After sufficient data collection, a structured psychological observation is generated and can be exported as PDF.

---

## ğŸ—ï¸ Architecture Highlights

### Modular Monolith Pattern
The application follows a **Blueprint-based modular design**, separating concerns into:
- **Routes** (`app/routes.py`) â†’ HTTP endpoints
- **SocketIO Events** (`app/socket_events.py`) â†’ Real-time communication
- **Services** (`app/services.py`) â†’ External API integrations
- **Models** (`app/models.py`) â†’ Data layer

This enables **independent testing, gradual microservice extraction**, and **team-based feature development**.

### Lazy Loading Optimization
Whisper model (461MB) is loaded **only on the first audio transcription request**, not at startup â€” reducing cold start time from ~30s to <3s.

### Environment Configuration
The `config.py` module supports multiple environments:
- `DevelopmentConfig` (debug=True, verbose logging)
- `ProductionConfig` (debug=False, gunicorn-ready)

---

## ğŸ” Security Considerations

- **Environment Variables**: API keys stored in `.env` (excluded from Git)
- **Password Hashing**: PBKDF2-SHA256 via Werkzeug
- **CSRF Protection**: Built-in Flask-WTF integration (future enhancement)
- **Local STT**: No patient data sent to third-party transcription services

---

## ğŸ³ Docker Details

### Dockerfile
- Base: `python:3.10-slim`
- System deps: `ffmpeg`, `build-essential`, `git`
- Layer caching: `requirements.txt` copied first for faster rebuilds
- Non-root user: Future TODO for security hardening

### docker-compose.yml
- **Port mapping**: `5001:5001`
- **Volumes**:
  - `whisper-cache:/root/.cache/whisper` (persistent model storage)
  - `./instance:/app/instance` (SQLite database)
- **Environment**: `.env` file auto-loaded

---

## ğŸ“Š Performance Notes

- **First audio transcription**: ~6-10s (model loading + inference)
- **Subsequent transcriptions**: ~1-2s (model cached in memory)
- **Whisper model size**: 461MB (small), 244MB (base), 1.5GB (medium)
- **LLM response time**: 2-5s (depends on OpenRouter load)

---

## ğŸ›£ï¸ Roadmap

- [ ] PostgreSQL migration for production
- [ ] Redis session store for horizontal scaling
- [ ] Celery task queue for async LLM processing
- [ ] DICOM integration for medical imaging
- [ ] Multi-language Whisper support (currently Turkish-optimized)
- [ ] Gunicorn + Nginx production deployment guide

---

## ğŸ¤ Contributing

This is a portfolio project demonstrating:
- Clean architecture principles
- Production-grade Docker setup
- Real-time WebSocket handling
- Local AI model integration

Feel free to fork and adapt for your use case.

---

## ğŸ“„ License

MIT License â€” See [LICENSE](LICENSE) for details.

---

## ğŸ‘¨â€ğŸ’» Author

**TuÄŸrul**  
*Full-Stack Developer | AI Engineering Enthusiast*

Built with Flask, Whisper, and a passion for healthcare tech.

---

**âš ï¸ Disclaimer**: This application is for **educational and research purposes only**. It is **not** a replacement for professional medical diagnosis. Always consult qualified healthcare providers for clinical decisions.
